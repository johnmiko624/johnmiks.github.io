<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>History and Basics of Computing</title>
    <style>
        body {
            background-color: #121212;
            color: #E0E0E0;
            font-family: 'Helvetica', Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.8;
        }
        header {
            background-color: #1F1F1F;
            padding: 20px;
            text-align: center;
            border-bottom: 3px solid #333;
        }
        header h1 {
            color: #76FF03;
            margin: 0;
            font-size: 2.5em;
        }
        nav {
            background-color: #2C2C2C;
            padding: 15px;
            text-align: center;
            margin-bottom: 30px;
        }
        nav a {
            color: #76FF03;
            margin: 0 20px;
            text-decoration: none;
            font-weight: bold;
            font-size: 1.2em;
        }
        nav a:hover {
            text-decoration: underline;
        }
        section {
            padding: 25px;
            margin: 25px;
            background-color: #1E1E1E;
            border-radius: 8px;
            box-shadow: 0px 0px 15px #000;
        }
        section h2 {
            color: #76FF03;
            border-bottom: 2px solid #333;
            padding-bottom: 10px;
            font-size: 2em;
        }
        section p {
            margin-bottom: 25px;
            text-align: justify;
            font-size: 1.1em;
        }
        .timeline {
            background-color: #333;
            padding: 25px;
            border-radius: 8px;
            margin: 25px 0;
        }
        .timeline h3 {
            color: #FFEB3B;
            font-size: 1.8em;
        }
        .timeline ul {
            list-style: none;
            padding: 0;
        }
        .timeline ul li {
            margin-bottom: 15px;
            padding: 12px;
            background-color: #444;
            border-left: 5px solid #76FF03;
            font-size: 1.1em;
        }
        .image-container {
            text-align: center;
            margin-bottom: 25px;
        }
        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0px 0px 15px #000;
        }
        footer {
            background-color: #1F1F1F;
            text-align: center;
            padding: 15px;
            border-top: 3px solid #333;
            margin-top: 50px;
        }
        footer p {
            color: #76FF03;
            margin: 0;
            font-size: 1.2em;
        }
    </style>
</head>
<body>

<header>
    <h1>History and Basics of Computing</h1>
</header>

<nav>
    <a href="#historical">Historical Perspective</a>
    <a href="#it-basics">IT Basics</a>
    <a href="#future">The Future of Computing</a>
</nav>

<section id="historical">
    <h2>Historical Perspective on Computing</h2>
    <div class="image-container">
        <img src="pic1.jpg" alt="Historical Computing">
    </div>
    <p>
        The history of computing is a rich tapestry that stretches back to ancient civilizations. Early devices like the abacus were used to perform simple calculations, laying the foundation for more complex systems. In the 19th century, Charles Babbage designed the Analytical Engine, a mechanical precursor to modern computers. Though it was never built in his lifetime, Babbage's ideas inspired future generations of engineers and computer scientists.
    </p>
    <p>
        As technology advanced, so did the complexity of computing machines. The 20th century saw the advent of electronic computers, with pivotal developments such as the ENIAC in 1945, which was one of the first general-purpose electronic digital computers. This period also saw the invention of the transistor in 1947, which replaced vacuum tubes and became a fundamental building block of modern electronics.
    </p>
    <div class="timeline">
        <h3>Key Milestones in Computing History:</h3>
        <ul>
            <li><strong>1941:</strong> Konrad Zuse creates the Z3, the world's first programmable computer.</li>
            <li><strong>1947:</strong> The transistor is invented, marking the beginning of the semiconductor era.</li>
            <li><strong>1957:</strong> IBM introduces FORTRAN, one of the first high-level programming languages.</li>
            <li><strong>1971:</strong> Intel releases the 4004 microprocessor, leading to the development of personal computers.</li>
            <li><strong>1981:</strong> IBM launches the first personal computer (PC), sparking the PC revolution.</li>
            <li><strong>1991:</strong> The World Wide Web becomes publicly accessible, transforming global communication.</li>
        </ul>
    </div>
    <p>
        The contributions of pioneers like Ada Lovelace, who is often credited as the first computer programmer, and Alan Turing, whose work laid the groundwork for modern computing, continue to resonate today. The evolution of computing has not only transformed technology but also reshaped society, influencing everything from industry to entertainment.
    </p>
</section>

<section id="it-basics">
    <h2>Introduction to IT Basics</h2>
    <div class="image-container">
        <img src="pic2.jpg" alt="IT Basics">
    </div>
    <p>
        Information Technology (IT) is an expansive field that encompasses everything from computers and networking to software and data management. At its core, IT is about the use of technology to manage and process information, making it accessible and usable for a wide range of applications.
    </p>
    <p>
        <strong>Hardware:</strong> The physical components of a computer system, such as the CPU, memory, storage devices, and peripherals, form the backbone of any IT system. Understanding how these components interact is essential for troubleshooting and optimizing system performance.
    </p>
    <p>
        <strong>Software:</strong> Software is the set of instructions that tells the hardware what to do. This includes everything from operating systems like Windows and Linux to applications like word processors, databases, and web browsers. The design and development of software are crucial aspects of IT, requiring a deep understanding of programming languages and algorithms.
    </p>
    <p>
        <strong>Networking:</strong> In today's connected world, networking is a critical component of IT. Networks allow computers to communicate with each other, sharing resources and data. Whether through local area networks (LANs) or wide area networks (WANs), networking enables the internet and countless other technologies that we rely on daily.
    </p>
    <p>
        <strong>Security:</strong> As our reliance on technology grows, so does the importance of IT security. Protecting systems from cyber threats, unauthorized access, and data breaches is a key responsibility of IT professionals. Security measures such as firewalls, encryption, and secure passwords are essential for safeguarding sensitive information.
    </p>
    <p>
        IT plays a vital role in modern organizations, enabling everything from day-to-day operations to long-term strategic planning. Whether in healthcare, finance, education, or entertainment, IT is the driving force behind innovation and efficiency.
    </p>
</section>

<section id="future">
    <h2>The Future of Computing</h2>
    <div class="image-container">
        <img src="pic3.jpg" alt="The Future of Computing">
    </div>
    <p>
        The future of computing is an exciting and rapidly evolving field, with advancements in areas such as quantum computing, artificial intelligence (AI), and the Internet of Things (IoT) promising to revolutionize the way we interact with technology.
    </p>
    <p>
        <strong>Quantum Computing:</strong> Unlike traditional computers, which use binary bits to process information, quantum computers use quantum bits or qubits. This allows them to perform complex calculations at unprecedented speeds, potentially solving problems that are currently intractable for classical computers. Quantum computing is still in its early stages, but its potential is enormous.
    </p>
    <p>
        <strong>Artificial Intelligence:</strong> AI is already transforming industries by automating tasks, improving decision-making, and creating new products and services. As AI technologies continue to advance, we can expect even greater integration into our daily lives, from personalized healthcare to autonomous vehicles.
    </p>
    <p>
        <strong>Internet of Things:</strong> The IoT connects everyday objects to the internet, enabling them to send and receive data. This creates opportunities for smarter homes, cities, and industries, where devices can communicate and collaborate to improve efficiency and quality of life. With the expansion of 5G networks, the IoT's capabilities will only grow.
    </p>
    <p>
        As we look ahead, it is important to consider the ethical implications of these advancements. Ensuring that technology benefits all of society, while addressing issues such as privacy, security, and access, will be crucial as we move into the next era of computing.
    </p>
</section>

<footer>
    <p>&copy; 2024 "History and Basics of Computing".-John Miko Sarsalijo All rights reserved.</p>
</footer>

</body>
</html>
